# 预设的问题


### 自我介绍

面试官，您好，我是XX，在读于怀化学院软件工程专业。从网上看到公司招聘的这个职位，觉得自己比较适合公司的岗位，对自己的发展也有帮助，所以来这里争取下这份工作，在校期间，学习过c语言，java语言，重点学习的是java语言，个人在java这条道路上已经走了两年了，掌握MySQL、Redis、


自我介绍例子:    2020-10-06更新
	面试官好, 我叫xxx, 是一名xxx大学的大四学生,xx公司是一家很有影响力的公司,我应聘的是java开发
	的工作,从事Java开发是我的爱好以及梦想,为此在学校里我很早就结合岗位要求进行了准备,包括对Java
	基础的理解与深入,各种框架的学习,以及一些组件比如Docker redis Nginx es git 以及mq等等,在
	学习的过程中呢,我也对这些技术在自己的项目上进行了相应的应用, 目前正在学习xx, 以后有可能的话
	还想转xx方向


通过Lottery视频给自己预设的问题列表：
（勿回复，学完课程自我解答。实在不会，再上提。避免部分问题懵懂过关.望各位大佬对问题答案发表自我评价与理解.帮我躲坑）
### 1. 啥是ddd？

官方介绍
- Domain Drive Design（领域驱动设计）
- 六边形架构模型
  
为什么要用ddd？

- 面向对象设计，数据行为绑定，告别贫血模型
- 降低复杂度，分而治之
- 优先考虑领域模型，而不是切割数据和行为
- 准确传达业务规则，业务优先
- 代码即设计
- 它通过边界划分将复杂业务领域简单化，帮我们设计出清晰的领域和应用边界，可以很容易地实现业务和技术统一的架构演进
- 领域知识共享，提升协助效率
- 增加可维护性和可读性，延长软件生命周期
- 中台化的基石
 
[参考前半部分](https://zhuanlan.zhihu.com/p/411866735)

在模块中以其中一个业务为核心，其它业务都是围绕这个业务来构建的

然后它又是分为四层，

1. application 应用层

对整个业务的逻辑进行编排，mq，xxl-job任务定时在这个层定义。

2. domain 领域层

业务整个逻辑，然后在领域层又分为多个包的模板，每个包又是一个逻辑，根据业务相互调用，都是围绕核心业务去建立，其他层都是围绕领域层去建立。

此项目中，在领域层实现：

- 用规则引擎去过滤用户，
- 抽奖的算法编排，通过hash散列斐波拉契算法 根据相对应的活动id去编排
- 抽到的奖品的发送，这里还要去涉及到物流，没写，


每个领域层都有对应的req，res对象

3. infrastructure 基础层

和数据库交互，然后实现domain 中 对外提供的仓储接口（仓储里的对象也是聚合的），存放实体类对象

4. interface 接口层

对外服务，相当于controller层，基本上就是引用应用层，然后是对象的转换。

-------------

可以去添加一个 comment 层，里面设置的是 结果类，枚举类 主要是一些通用的，然后以这个层会被所有的层都使用。通过maven去引入。comment 不去引入其他层的依赖，基本上就不会造成循环依赖问题。

如果需要服务之间的调用 添加一个rpc层，对外踢动rpc服务调用。



### 2. 领域服务是啥？

当一些逻辑不属于某个实体时，可以把这些逻辑单独拿出来放到领域服务中 理想的情况是没有领域服务，如果领域服务使用不恰当慢慢又演化回了以前逻辑都在service层的局面。

可以使用领域服务的情况：

- 执行一个显著的业务操作
- 对领域对象进行转换
- 以多个领域对象作为输入参数进行计算，结果产生一个值对象

领域层(domain)

- 领域服务位于领域层，为完成领域中跨实体或值对象的操作转换而封装的服务，领域服务以与实体和值对象相同的方式参与实施过程。
- 领域服务对同一个实体的一个或多个方法进行组合和封装，或对多个不同实体的操作进行组合或编排，对外暴露成领域服务。领域服务封装了核心的业务逻辑。实体自身的行为在实体类内部实现，向上封装成领域服务暴露。
- 为隐藏领域层的业务逻辑实现，所有领域方法和服务等均须通过领域服务对外暴露。
- 为实现微服务内聚合之间的解耦，原则上禁止跨聚合的领域服务调用和跨聚合的数据相互关联。



### 3. otter是啥？

定位： 基于数据库增量日志解析，准实时同步到本机房或异地机房的mysql/oracle数据库. 一个分布式数据库同步系统。Ottter是由阿里开源的一个数据同步产品,它的最初的目的是为了解决跨国异地机房双A架构,两边可写的场景,开发时间从2011年7月份一直持续到现在，目前阿里巴巴B2B内部的本地/异地机房的同步需求基本全上了Otter。Otter基于数据库增量日志解析，支持mysql/oracle数据库进行同步,也有全量同步的，如果我们有全表更新或者想要历史数据的需求怎么办？这就涉及到otter的ziyou门功能。


**otter特性**

- 使用纯JAVA开发,占时资源比较高
- 基于Canal获取数据库增量日志,Canal是阿里爸爸另外一个开源产品
- 使用manager(web管理)+node(工作节点),manager负责配置监控,node负责处理任务
- 基于zookeeper,解决分布式状态调度的，允许多node节点之间协同工作
- 使用aria2多线程传输技术,对网络依赖带宽依赖较低

[参考otter入门2015的](https://www.cnblogs.com/duanxz/p/5008837.html)


### 4. elk是啥?

ELK实际上是三个工具的集合，Elasticsearch + Logstash + Kibana，这三个工具组合形成了一套实用、易用的监控架构，很多公司利用它来搭建可视化的海量日志分析平台。

1. es

ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。

2. logstash

Logstash是一个用于管理日志和事件的工具，你可以用它去收集日志、转换日志、解析日志并将他们作为数据提供给其它模块调用，例如搜索、存储等。

3. kibana

Kibana是一个优秀的前端日志展示框架，它可以非常详细的将日志转化为各种图表，为用户提供强大的数据可视化支持。

[参考](https://blog.csdn.net/dengqingyuan123/article/details/89509197)

### 5. ddd四层架构是啥？

看问题1


**ddd与mvc的区别和联系**

将service层划分为应用层和领域层。

- 在架构设计上，在DDD分层结构中将传统三层架构的业务逻辑层拆解为应用层和领域层
其中Application划分为很薄的一层服务，非核心的逻辑放到此层去实现，核心的业务逻辑表现下沉到领域层去实现，凝练为更为精确的业务规则集合，通过领域对象去阐述说明。

- 在建模方式上，DDD分层的建模思维方式有别于传统三层
传统三层通常是以数据库为起点进行数据库分析设计，而DDD则需要以业务领域模型为核心建模（即面向对象建模方式），更能体现对现实世界的抽象。
故在DDD分层凸显领域层的重要作用，领域层为系统的核心，包括所有的业务领域模型的抽象表达。

- 在职责划分上，基础设施层涵盖了2方面内容
  - 持久化功能，其中原三层架构的数据访问层下沉到基础设施层的持久化机制实现
  - 通用技术支持，一些公共通用技术支持也放到基础设施层去实现。

## 6. 领域驱动设计是啥？


**什么是领域驱动设计**

领域驱动设计的概念是2004年Evic Evans在他的著作《Domain-Driven Design : Tackling Complexity in the Heart of Software》（中文译名：领域驱动设计：软件核心复杂性应对之道）中提出的。

DDD是一种通过把设计实现与不断修正发展的模型紧密关联起来，来应对复杂需求的一种软件开发思路。

Evic Evans在著作中将软件系统的设计分为2个部分：战略设计和战术设计。
- 在战略设计层面提出了域、子域、限界上下文等重要概念；
- 在战术设计层面提出了实体、值对象、领域服务、领域事件、聚合、工厂、资源库等重要概念。

战略设计部分指导我们如何拆分一个复杂的系统，战术部分指导我们对于拆分出来的单个子系统如何进行落地，在落地过程中应该遵循哪些原则。

[参考](https://blog.csdn.net/qq_34370153/article/details/104175903)
[参考二](https://zhuanlan.zhihu.com/p/164757995)



### 7. 数据库路由描述！

动态的进行数据库表匹配和数据库 库匹配

### 8. x-pack-jdbc 是啥？

高级特性，是指 Elasticsearch 官方商业特性（原 X-Pack 商业版插件包含的特性），包含了安全（Security）、SQL、机器学习（Machine Learning）、监控（Monitor）等高级功能，可以为 Elasticsearch 服务的应用开发和运维管理，提供更有力的帮助。

elk 的系统组件 x-pack。一个集安全、警报、监视、报告和图形功能于身的扩展，轻松开启或关闭那你想要的功能。

- 安全
- 用户管理
- 日志审计
- X-pack monitor会快速提供elasticsearch 、logstash、kibana的的性能。实时展示他们的健康状况！
- 强大的监控系统，清晰的数据，有利于我们对资源的合理利用。
- 告警功能（alerting）
- 报告功能（Reporting）

[参考](https://zhuanlan.zhihu.com/p/36337697)


### 9. skywalking是啥？

[官网](https://skywalking.apache.org/docs/skywalking-showcase/next/readme/)

kywalking是分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（Docker、K8s、Mesos）架构而设计。SkyWalking 是观察性分析平台和应用性能管理系统。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案（官网介绍）。

SkyWalking：国人(吴晟)开发，支持dubbo，SpringCloud，SpringBoot集成，代码无侵入，通信方式采用GRPC，性能较好，实现方式是java探针，支持告警，支持JVM监控，支持全局调用统计等等，功能较完善。缺点是依赖较多，需要ElasticSearch，JDK环境，Nacos注册中心等。是基于Open Tracing规范开发的。

特点：

- 多种监控手段。可以通过语言探针和 service mesh 获得监控是数据。
- 多个语言自动探针。包括 Java，.NET Core 和 Node.JS。
- 轻量高效。无需大数据平台，和大量的服务器资源。
- 模块化。UI、存储、集群管理都有多种机制可选。
- 支持告警。
- 优秀的可视化解决方案。

![pS1fe9e.png](https://s1.ax1x.com/2023/01/17/pS1fe9e.png)

架构主要有四个部分。

- 上面的Agent：负责从应用中，收集tracing(调用链数据)和metric(指标)，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给SkyWalking OAP 服务器。
- 中间的SkyWalking OAP：负责接收 Agent 发送的 Tracing 和Metric的数据信息，然后进行分析(Analysis Core) ，存储到外部存储器( Storage )，最终提供查询( Query )功能。
- 左边的SkyWalking UI：负责提供web控制台，查看链路，查看各种指标，性能等等。
- 数据存储。目前支持ES、MySQL、H2等多种存储器。

可以在Spring体系中使用

[参考](https://skywalking.apache.org/zh/2020-04-19-skywalking-quick-start/#6-spring-boot-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B)
[SkyWalking入门](https://zhuanlan.zhihu.com/p/365817489)


### 10. pinpoint是啥？

[github](https://github.com/pinpoint-apm/pinpoint)

什么是Pinpoint
2012年七月开始开发，在2015年1月作为一个开源项目启动

Pinpoint是一个用Java/PHP写的开源的应用于大规模分布式系统的应用系统管理工具

- Pinpoint是一个开源的 APM (Application Performance Management/应用性能管理)工具， 用于基于java的大规模分布式系统。
- 仿照 Google Dapper , Pinpoint 通过跟踪分布式应用之间的调用来提供解决方案， 以帮助分析系统的总体结构和内部模块之间如何相互联系。
- 如今的服务通常由很多不同模块组成，他们之间相互调用并通过API调用外部服务。 每个交互是如何被执行的通常是一个黑盒。 Pinpoint跟踪这些模块之间的调用流并提供清晰的视图来定位问题区域和潜在瓶颈。

优势：
- 强大的UI
- 调用链信息全
- 高性能
  
![pS1frNT.png](https://s1.ax1x.com/2023/01/17/pS1frNT.png)

由Pinpoint官方给出的架构图我们可以看出，Pinpoint Agent负责采集用户程序的信息 通过 网络将信息发给服务端 Pinpoint Collector，Pinpoint Collector将数据持久化到Hbase中，前端Web UI从Hbase中读取数据展示给用户。是一个标准的C/S分布式架构，选中Hbase的原因想必是为了支持海量数据。


[参考](https://cloud.tencent.com/developer/article/1694068)



### 11. 三高问题是啥？

高性能，高并发，高可用

![pS1hrqI.png](https://s1.ax1x.com/2023/01/17/pS1hrqI.png)

**缓存**

- 缓存之所以有效在于二八定律（缓存之所以能够大幅提高系统的性能，关键在于数据的访问具有局部性，也就是二八定律：「百分之八十的数据访问是集中在 20% 的数据上」。这部分数据也被叫做热点数据。）
- 本地缓存  （使用进程内成员变量或者静态变量）
- 分布式缓存 一致性 Hash 算法
- 缓存适用场景： 读多写少，计算好使大，且实时性不高
- 不适合缓存的场景：写多读少，频分更新。对数据一致性要求严格。数据访问完全随机。
- 缓存更新的策略：Cache-Aside，Cache-As-SoR

**预处理和延后处理**

预先延后，这其实是一个事物的两面，不管是预先还是延后核心思想都是将本来该在实时链路上处理的事情剥离，要么提前要么延后处理。降低实时链路的路径长度， 这样能有效提高系统性能。

数据库的 TPS（每秒处理的事务数）

延后处理还有一个非常著名的例子，COW（Copy On Write，写时复制）。 Linux 创建进程的系统调用 fork，fork 产生的子进程只会创建虚拟地址空间，而不会分配真正的物理内存，子进程共享父进程的物理空间，只有当某个进程需要写入的时候，才会真正分配物理页，拷贝该物理页，通过 COW 减少了很多不必要的数据拷贝。

**池化**

后台开发过程中你一定离不开各种 「池子」： 内存池、连接池、线程池、对象池......

内存、连接、线程这些都是资源，创建线程、分配内存、数据库连接这些操作都有一个特征， 那就是创建和销毁过程都会涉及到很多系统调用或者网络 IO。 每次都在请求中去申请创建这些资源，就会增加请求处理耗时，但是如果我们用一个 容器（池） 把它们保存起来，下次需要的时候，直接拿出来使用，避免重复创建和销毁浪费的时间。

- 内存池
- 线程池 （四个核心组成部分：管理器，工作线程，任务接口，任务队列）
- 连接池 （数据库连接池）

池化实际上是预处理和延后处理的一种应用场景，通过池子将各类资源的创建提前和销毁延后。

**同步变异步**

对于处理耗时的任务，如果采用同步的方式，那么会增加任务耗时，降低系统并发度。

可以通过将同步任务变为异步进行优化。

但是异步编程往往需要回调函数（Callback function），如果回调函数的层级太深，这就是回调地狱（Callback hell）。

**消息队列**

这是一个非常简化的消息队列模型，上游生产者将消息通过队列发送给下游消费者。在这之间，消息队列可以发挥很多作用，比如：

- 服务解耦 （这样如果需要新增一个数据分析的服务，那么又得改动发布服务，这违背了依赖倒置原则，即上层服务不应该依赖下层服务，那么怎么办呢？）
- 异步处理  （有些业务涉及到的处理流程非常多，但是很多步骤并不要求实时性。那么我们就可以通过消息队列异步处理。比如淘宝下单，一般包括了风控、锁库存、生成订单、短信/邮件通知等步骤。但是核心的就风控和锁库存， 只要风控和扣减库存成功，那么就可以返回结果通知用户成功下单了。后续的生成订单，短信通知都可以通过消息队列发送给下游服务异步处理。大大提高了系统响应速度。这就是处理流程异步化。）
- 流量削峰  （一般像秒杀、抽奖、抢卷这种活动都伴随着短时间海量的请求， 一般超过后端的处理能力，那么我们就可以在接入层将请求放到消息队列里，后端根据自己的处理能力不断从队列里取出请求进行业务处理。）


消息队列的核心思想就是把同步的操作变成异步处理，异步处理会带来相应的好处，比如:

- 服务解耦
- 提高系统的并发度，将非核心操作异步处理，不会阻塞住主流程

但是软件开发没有银弹，所有的方案选择都是一种 trade-off。 同样，异步处理也不全是好处，也会导致一些问题：

- 降低了数据一致性，从强一致性变为最终一致性
- 有消息丢失的风险，比如宕机，需要有容灾机制

**批量处理**

在涉及到网络连接、IO等情况时，将操作批量进行处理能够有效提高系统的传输速率和吞吐量。

在前后端通信中，通过合并一些频繁请求的小资源可以获得更快的加载速度。

比如我们后台 RPC 框架，经常有更新数据的需求，而有的数据更新的接口往往只接受一项，这个时候我们往往会优化下更新接口，

使其能够接受批量更新的请求，这样可以将批量的数据一次性发送，大大缩短网络 RPC 调用耗时。


##### **数据库**

**索引**
先把我认为索引必知必会的知识列出来，大家可以查漏补缺:

- 主键索引和普通索引，以及它们之间的区别
- 最左前缀匹配原则
- 索引下推
- 覆盖索引、联合索引

**读写分离**

读写分离到之后就避免了读写锁争用，这里解释一下，什么叫读写锁争用：

MySQL 中有两种锁:

- 排它锁( X 锁)： 事务 T 对数据 A 加上 X 锁时，只允许事务 T 读取和修改数据 A。
- 共享锁( S 锁)： 事务 T 对数据 A 加上 S 锁时，其他事务只能再对数据 A 加 S 锁，而不能加 X 锁，直到 T 释放 A 上的 S 锁。

读写分离解决问题的同时也会带来新问题，比如主库和从库数据不一致

MySQL 的主从同步依赖于 binlog，binlog(二进制日志)是 MySQL Server 层维护的一种二进制日志，是独立于具体的存储引擎。它主要存储对数据库更新(insert、delete、update)的 SQL 语句，由于记录了完整的 SQL 更新信息，所以 binlog 是可以用来数据恢复和主从同步复制的。

从库从主库拉取 binlog 然后依次执行其中的 SQL 即可达到复制主库的目的，由于从库拉取 binlog 存在网络延迟等，所以主从数据存在延迟问题。

**分库分表**


**具体技法**

- 零拷贝

高性能的服务器应当避免不必要数据复制，特别是在用户空间和内核空间之间的数据复制。

如果了解 Linux IO 的话就知道这个过程包含了内核空间和用户空间之间的多次拷贝：


内核空间和用户空间之间数据拷贝需要 CPU 亲自完成，但是对于这类数据不需要在用户空间进行处理的程序来说，这样的两次拷贝显然是浪费。什么叫 「不需要在用户空间进行处理」？

比如 FTP 或者 HTTP 静态服务器，它们的作用只是将文件从磁盘发送到网络，不需要在中途对数据进行编解码之类的计算操作。

如果能够直接将数据在内核缓存之间移动，那么除了减少拷贝次数以外，还能避免内核态和用户态之间的上下文切换。

而这正是零拷贝（Zero copy）干的事，主要就是利用各种零拷贝技术，减少不必要的数据拷贝，将 CPU 从数据拷贝这样简单的任务解脱出来，让 CPU 专注于别的任务。

常用的零拷贝技术:

1. mmap

mmap通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数。

2. sendfile

sendfile是 Linux2.1 版本提供的，数据不经过用户态，直接从页缓存拷贝到 socket 缓存，同时由于和用户态完全无关，就减少了一次上下文切换。

在 Linux 2.4 版本，对 sendfile 进行了优化，直接通过 DMA 将磁盘文件数据读取到 socket 缓存，真正实现了 ”0” 拷贝。前面 mmap 和 2.1 版本的 sendfile 实际上只是消除了用户空间和内核空间之间拷贝，而页缓存和 socket 缓存之间的拷贝依然存在。

- 无锁化

在多线程环境下，为了避免 竞态条件（race condition）， 我们通常会采用加锁来进行并发控制，锁的代价也是比较高的，锁会导致上线文切换，甚至被挂起直到锁被释放。

基于硬件提供的原子操作 CAS(Compare And Swap) 实现一些高性能无锁的数据结构，比如无锁队列，可以在保证并发安全的情况下，提供更高的性能。

首先需要理解什么是 CAS，CAS 有三个操作数，内存里当前值M，预期值 E，修改的新值 N，CAS 的语义就是：

如果当前值等于预期值，则将内存修改为新值，否则不做任何操作。

- 序列化和反序列化

所有的编程一定是围绕数据展开的，而数据呈现形式往往是结构化的，比如结构体（Struct）、类（Class）。 但是当我们 通过网络、磁盘等传输、存储数据的时候却要求是二进制流。 比如 TCP 连接，它提供给上层应用的是面向连接的可靠字节流服务。那么如何将这些结构体和类转化为可存储和可传输的字节流呢？这就是序列化要干的事情，反之，从字节流如何恢复为结构化的数据就是反序列化。

序列化解决了对象持久化和跨网络数据交换的问题。

序列化一般按照序列化后的结果是否可读，可分为以下两类：

- 文本类型:

如 JSON、XML，这些类型可读性非常好，是自解释的。也常常用在前后端数据交互上，因为接口调试，可读性高非常方便。但是缺点就是信息密度低，序列化后占用空间大。

- 二进制类型

如 Protocol Buffer、Thrift等，这些类型采用二进制编码，数据组织得更加紧凑，信息密度高，占用空间小，但是带来的问题就是基本不可读。

还有 Java 、Go 这类语言内置了序列化方式，比如在 Java 里实现了 Serializable 接口即表示该对象可序列化。

序列化将对象和类转化为可存储可传输的字节流。




[全文参考-很好的一篇文章](https://mp.weixin.qq.com/s/zjtD6ks5H516RB3iaGapIw)



### 12. 充血模型是啥？

- 贫血模型：

定义对象的简单的属性值，没有业务逻辑上的方法

所谓贫血模型，是指Model中，仅包含状态（属性），不包含行为（方法），采用这种设计时，需要分离出DB层，专门用于数据库操作。

贫血模型是指业务逻辑全部放在service层，业务对象只包含数据不包含业务逻辑

- 充血模型：

充血模型也就是我们在定义属性的同时也会定义方法，我们的属性是可以通过某些方式直接得到属性值，那我们也就可以在对象中嵌入方法直接创建出一个具有属性值的对象。就是说这个对象不再需要我们在进行进一步的操作，这也就复合了OOP的三大特性之一的封装


Model 中既包括状态，又包括行为，是最符合面向对象的设计方式。


根本在领域层中实现了相对应的属性和方法，不需要在一个类中，在领域层中包含了service、model和Irepository


### 13. 拒绝泥球单体是啥?

结构随意、杂乱无序、臃肿肥大

### 14. 拒绝领域污染是啥?

个人理解，应该是在领域层不应该有属于其他层的结构与类在此领域中实现。

### 15. 领域分层是啥?

不同的业务在领域层中·也是要进行分层的。比如：抽奖策略和发奖流程，在领域层也是要分层的。

### 16. 领域编排是啥?

编 编写，排 排列，将整个业务逻辑进行编排，然后提供给应用层使用，看提供这个阶段是否需要解决什么问题。

### 17. 斐波那契是啥?

斐波那契在数学中，从n=2开始，当前的值都是前面二个值之和。前一项与后一项的比值会越来越逼近斐波拉契0.618。

### 18. rpc是啥?

rpc是一种远程服务调用协议，让客户端不知道细节，调用远程对象和调用本地对象一样。

常见的rpc框架有dubbo，grpc，thift，然后还有个微博的。

原理：

通信流程的八个阶段。

### 19. 散列扰动是啥?

参考hashmap中的扰动函数，``(h = key.hashCode()) ^ (h >>> 16)`` 参考哈希值右移16位，也就正好是自己长度的一半，之后与原哈希值做异或运算，这样就混合了原哈希值中的高位和地位，增大了随机性。

### 20. 任务补偿是啥?

回滚

- 利用定时任务的方式，频繁的扫表，会造成网络IO和磁盘IO的消耗，不咋滴。

- 利用延迟队列，Rabbitmq本身没有延迟队列，是基于死信交换机和消息的存活时间TTL，来实现的。
关于死信交换机，定义一个交换机可以对应多个死信队列。在消息被consumer拒收，或者设置消息的TTL时间消息过期了，就会被放到死信队列。
这里消息和队列都可以设置TTL，最终取最小的的那个TTL时间。

对于需要回滚的任务，会进入到死信队列中，然后简历补偿消费者队列监听死信队列来进行任务回滚

- Redis延迟队列，
Redis延迟队列优势

1.zset数据结构支持高性能的score排序 2.内存操作，速度非常快 3.redis有哨兵和cluster集群模式，当消息多的时候可以使用集群模式处理 4.redis的持久化机制，保证数据的可持久性


1.mq具有生产者的confirm机制和消费者的ack确认机制 2.没有重试机制，需要自己实现和重试次数


延迟队列设计思路
1.将redis做消息池 KV结构：K=prefix+projectName field = topic+jobId V=CONENT;V由客户端传入的数据，消费的时候回传
2.zset做延迟优先队列，score做优先级
3.list结构，做消息队列先进先出的方式进行消费
4.zset和list存储消息地址
5.点对点消息从zset路由到list队列
6.定时器维护路由
7.ttl规则实现消息的延迟

[参考](https://zhuanlan.zhihu.com/p/252463222#:~:text=%E5%AF%B9%E4%BA%8E%E8%A7%A6%E5%8F%91%E5%A4%B1%E8%B4%A5%E7%9A%84%E4%BB%BB,%EF%BC%8C%E8%A1%A5%E5%81%BF%E8%A7%A6%E5%8F%91%E5%8D%B3%E5%8F%AF%E3%80%82)

### 21. db-router-spring-boot-starter具体干了些啥?

1. 进行AOP切面，构造mybatis拦截器，
2. 构造注解，进行分库与分表

### 22. shardingsphere是啥？怎么使用?

1. Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈，它由 JDBC、Proxy 和 Sidecar（规划中）这 3 款相互独立，却又能够混合部署配合使用的产品组成。 它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。
2. Apache ShardingSphere 定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的计算和存储能力，而并非实现一个全新的关系型数据库。 它通过关注不变，进而抓住事物本质。关系型数据库当今依然占有巨大市场，是各个公司核心业务的基石，未来也难于撼动，我们目前阶段更加关注在原有基础上的增量，而非颠覆。
3. Apache ShardingSphere 5.x 版本开始致力于可插拔架构，项目的功能组件能够灵活的以可插拔的方式进行扩展。 目前，数据分片、读写分离、多数据副本、数据加密、影子库压测等功能，以及 MySQL、PostgreSQL、SQLServer、Oracle 等 SQL 与协议的支持，均通过插件的方式织入项目。 开发者能够像使用积木一样定制属于自己的独特系统。Apache ShardingSphere 目前已提供数十个 SPI 作为系统的扩展点，仍在不断增加中。


**sharding-JDCB**

​ 定位为轻量级Java框架，在Java的JDBC层提供的额外服务。 它使用客户端直连数据库，以jar包形式提供服务，无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。

- 适用于任何基于JDBC的ORM框架，如：JPA，适用于任何基于JDBC的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使用JDBC。
- 支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP等。
- 支持任意实现JDBC规范的数据库。目前支持MySQL，Oracle，SQLServer，PostgreSQL以及任何遵循SQL92标准的数据库。

**sharding-proxy**

定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。 目前先提供MySQL/PostgreSQL版本，它可以使用任何兼容MySQL/PostgreSQL协议的访问客户端(如：MySQL Command Client, MySQL Workbench, Navicat等)操作数据，对DBA更加友好。

- 向应用程序完全透明，可直接当做MySQL/PostgreSQL使用。
- 适用于任何兼容MySQL/PostgreSQL协议的的客户端。


**sharding-sidecar**

​ 定位为Kubernetes的云原生数据库代理，以Sidecar的形式代理所有对数据库的访问。 通过无中心、零侵入的方案提供与数据库交互的的啮合层，即Database Mesh，又可称数据网格。

​ Database Mesh的关注重点在于如何将分布式的数据访问应用与数据库有机串联起来，它更加关注的是交互，是将杂乱无章的应用与数据库之间的交互有效的梳理。使用Database Mesh，访问数据库的应用和数据库终将形成一个巨大的网格体系，应用和数据库只需在网格体系中对号入座即可，它们都是被啮合层所治理的对象。



**核心概念**

1. 逻辑表 （从0开始）
2. 真实表   分片的数据库中真实存在的物理表
3. 数据节点  数据分片的最小单元。由数据源名称和数据表组成
4. 绑定表   ​ 指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。
5. 广播表 ​ 指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中均完全一致。
6. 分片键   用于分片的数据库字段，是将数据库(表)水平拆分的关键字段。
7. 分片算法 
8. 分片策略


[详情参看](https://www.cnblogs.com/ityml/p/14968027.html)

[官网](https://shardingsphere.apache.org/index_zh.html)


### 23. mycat是啥？怎么使用

从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了MySQL协议的Server，前端用户可以把它看做是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生（Native）协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分库分表，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。

核心功能同样是分库分表

支持主流数据库，MongoDB等NoSQL存储。


**原理**

主要是拦截，拦截了用户发送过来的SQL语句，首先对SQL语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此SQL发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。


**应用场景**

1. 单纯的读写分离
2. 分表分库
3. 多租户应用
4. 报表系统
5. 代替HBASE，分析大数据
6. 作为海量数据实时查询的一种方案，比如100亿条频繁查询的记录需要在3秒内查询出结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时MyCat可能是最简单有效的选择。

[详情请看](https://zhuanlan.zhihu.com/p/81916501)
[官网](http://www.mycat.org.cn/)

### 24. lvs是啥？

概念：Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统

作用：主要是用于服务器的负载均衡，工作在网络层，可以实现高性能，高可用的服务器集群技术。

**工作原理**

分为三层：

1. Load Balancer：这是LVS的核心部分，它好比我们网站MVC模型的Controller。

它负责将客户的请求按照一定的算法分发到下一层不同的服务器进行处理，自己本身不做具体业务的处理。

另外该层还可用监控下一层的状态，如果下一层的某台服务器不能正常工作了，它会自动把其剔除，恢复后又可用加上。

该层由一台或者几台Director Server组成。

2. Server Array：改层负责具体的业务。
3. Shared Storage：主要是提高上一层数据和为上一层保持数据一致。


**负载均衡的机制**

前面我们说了LVS是工作在网络层。相对于其它负载均衡的解决办法，比如DNS域名轮流解析、应用层负载的调度、客户端的调度等，它的效率是非常高的。

LVS的通过控制IP来实现负载均衡。IPVS是其具体的实现模块。

IPVS的主要作用：安装在Director Server上面，在Director Server虚拟一个对外访问的IP（VIP）。

1. NAT

网络地址翻转技术实现虚拟服务器。

2. TUN

即IP隧道技术实现虚拟服务器。

3. DR
   
直接路由技术返回服务器。

[lvs学习](https://www.cnblogs.com/Rivend/p/12071156.html)



### 25. jenkins 搭建与使用?
### 26. F5是啥?
### 27. LEPUS是啥?
### 28. google Dapper是啥?
### 29. 系统监控中的TP99,TP999,OPS,TPS,可用率,响应时长,负载,IO,网络,慢查询,事务,连接数分别是啥?通过什么工具查看?
TP99: 就是满足99%的网络请求所需要的最低耗时。TP99=10ms，标识这段时间99%的请求都在10毫秒以内。
TP999: TP999就是满足999‰的网络请求所需要的最低耗时。
tp其他同理;
MAX:MAX就是这段时间内耗时最大的，比如MAX=1000ms，表示这段时间最耗时的一次请求是1s，max高表示偶有一次请求，耗时很大。

- QPS：每秒查询率，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准
- TPS：每秒事务数。
- 
### 30. pom文件中dependencies和dependencyManagement的区别?
### 31. 开发规范
### 32. 基础层如何通过依赖反转的方式为各层提供基础服务?并举例!
### 33. 应用层的应用服务和领域事件服务分别是啥?
### 34. 领域服务是啥?
### 35. 基础服务中的仓储服务是啥?举例!
### 36. 接口服务是啥?举例!
### 37. 充血模型结构是啥?
### 38. 段落描述描述内容不懂
那么，这里还有一点就是DDD结构它是一种充血模型结构，所有的服务实现都以领域为核心，应用层定义接口，领域层实现接口，领域层定义数据仓储，基础层实现数据仓储中关于DAO和Redis的操作，但同时几方又有互相的依赖。
.


### 39. 通过这个抽奖项目你可以扩展到其他项目吗？

只要是一个业务逻辑项目，比如根据积分去兑换奖品，但是积分怎么获得呢，通过对老师的邀请，这就需要和其他模块对接。积分兑换就是一个核心的业务，积分的获得，积分的存取，奖品的展示，所有积分对应奖品的多少，相这种积分对应是一个区间还是一个固定的点，怎么去实现的？区间的话规则树的判断，固定的点也一样，加个字段？


### 40. C/S架构和B/S架构

[参考](https://zhuanlan.zhihu.com/p/71222679)

要去思考你项目中的每个任务，每个步骤，如果失败了会怎么样

### 41. 项目中表的设计，怎么回答？

1. 先介绍业务；抽奖系统作为营销活动平台中的一个环节，承接着活动玩法、积分消耗、奖品发放等系统的纽带，帮助整个业务完成用户的活跃。
2. 后阐述领域；作为一个战略设计的一环，战术实现上要尽可能做到职责隔离，对应系统的具体实现上要拆分出；活动、算法、规则、策略、用户、订单等领域。
3.  引入表设计；根据领域驱动中对各个模块的定义，设计数据库表，也就对应了活动表、抽奖策略配置表、准入规则引擎表、用户抽奖单记录表、以及配合这些表数据结构运行的其他表，如：记录用户的参与次数等。

# 面试项目

### 1. 像抽奖系统，一般部署多少实例比较合适，系统大概能抗住多大的流量？

如果按照抽奖系统 TPS 5000~8000 服务器配置大概情况；

1. Redis 集群访问，. Redis 集群服务，基本申请个16G就够了
2. QPS 约等于 TPS 的8~10倍，有时候不同业务也有不同的情况。
3. 分库分表，解决连接数瓶颈、解决数据增量，通常可能数据存量200万-300万增量在单表50万就会拆了（可能最开始很小，都设计成分库分表，因为分库分表很成熟，不会因为引入后导致开发效率低），因为拆分的库大多数也是虚拟机，并不会浪费多少服务器资源。后续数据量真大了，在迁移物理机。而分库分表后，数据就分散了，不用集中打到某个库表上。
4. TPS 8k 左右，qps 8w 差不多有10台-15台虚拟机就够了，4核8G的。15台虚拟机约等于1台物理机。1台物理机大概64核，2T的。
   
由于抽奖系统主要依赖于业务场景、活动效果、push范围、人群圈定，所以它的流量不是特别能预估准，一般会根据以往经验值。所以即使面试中，说一个这样的大概配置和应对的流量也是没问题的。



### 2. 抽奖系统为什么自研路由组件？

应实际秒杀峰值场景 TPS 5000 ~ 8000 的诉求，开发统一路由组件，不仅可以满足差异化不同字段的分库和分表组合，以及 Redis 库存分片和秒杀滑动库存分块，开发统一路由 Xdb-router-spring-boot-starter 的 SpringBoot Starter 技术组件。此套组件经历数次大促活动场景，支持横向扩展，可以满足业务规模的快速增长。


1. 公司内部技术栈建设时，类似mycat不能满足，ss（最早还没有使用）还没有完全稳定。不过目前内部也有部分项目使用ss
2. 自研组件比较成熟，不仅支持mysql，也支持redis路由到各自的服务，扩展功能比较方便。项目小而精，比较易于维护使用。
3. 在路由字段设计上，支持单字段支持分库分表，也支持x字段分库，y字段分表等。同时也添加了我们内部的监控在路由设计上。
4. 综上基于这些方面所以可以回答，ss 不是不能使用，只是我们选择更适合我们目前场景，低维护成本，提高研发交付的方式进行开发。



### 3. 分布式事务是怎么解决的？

1. 其实是这样的，使用对于跨库的事务处理，一种是分布式事务，另外一种就是基于MQ+任务调度补偿的方式，完成最终一致性。

2. 那么鉴于抽奖系统的实时性要求，从用户流程体验上，希望更加流畅，支撑更大的并发量，而不是对整个流程添加过多的事务，降低性能。因为事务来说，是一种集中化的竞态，所以这部分设计上采用最终一致性的方式进行处理，而不是直接添加大块的事务。

3. 此外由于营销场景的多样性和复杂性，自定义路由组件，可能更好的适应短平快的变化，如我们这样的系统中添加的路由，不仅可以支持数据库路由，也支持Redis路由，避免热key都打到一个服务上。在库存分片后，可以支撑更大的秒杀体量。同时对于单key的秒杀，还采用了滑块分段锁的方式进行处理，所以整个流程来看，都是希望是去中心化的，提高吞吐量的。

4. 当然，也可以储备些分布式事务的知识，这样也可以说明某些其他项目在用，表明不是你不会这样的技术，只是在适合的场景使用最合适的方案处理问题。



### 4. 项目中是怎么具体实现最终一致性的？

1. 查阅这个流程；redis库存扣减、写入记录、发送mq、接收mq更新数据库。如果是分布式事务，可以把跨库的扣减、写入记录都一起做。


但是这种方式不保证实时性？

这到不会，主要还是看流程设计。比如用户下单、支付、发货，那么是从下流水单开始，用流水单创建支付订单，写台账，唤起收银台支付。那么这个流程就是拆分开的，保持了最终一致性，告知每一步用户所处的动作就可以了。其他业务流程也类似。


**在首次领取活动哪里，会发送mq消息为了库存和redis一致性？ 这个地方只是确保了库存中的一致性。**



我看代码中是用Redis拦截了，redis key为null的时候才从数据库里加载，不为null的时候就直接用redis里的，然后异步MQ去更新数据库



### 5. mq重发的时候怎么去确保幂等性？

对于幂等性处理流程；

1. 使用Redis缓存对于重复的MQ进行消费记录，一般记录个12小时，短一点也可以。
2. 消费前如果缓存没有记录，可以查询数据库，消费过进行缓存记录。
3. 最终重要的，一般对于金融、订单、支付等场景，必须使用数据库防重字段做强一致性拦截处理，避免重复消费造成资损和客诉。



### 6. redis的key是用消息的消息id？还是业务唯一键？

业务唯一ID，不过有时候消息ID里设置的也是这个ID

刚好遇到一种场景，上游同时发送两个相同业务唯一键的消息-A和B。正常来说是先消费A再消费B，但是由于各种原因B先到A后到，这样会导致B的修改被覆盖了。我们在消息中加了时间戳来判断先后，你觉得有更好的方案不？

如果有消息挤压的情况下是会有这种情况，一般来说不太会设计顺序消费，可能会导致挤压更加严重。所以首先看看是否可以从设计上处理下。如果不能处理那么 MQ 来说本身是可以配置顺序消费的，再者是给MQ标记你说的时间戳。

[记录](https://blog.csdn.net/zhuqiuhui/article/details/103003733)



### 7. 被问到qps、tps这些指标如何回答？

其实可以从下面几个角度出发，把知识全部串起来，仅供个人参考：

1. 先说单机的qps、tps，记得核心关键词为高吞吐、低延迟，然后说一下具体的参数，比如说：机器配置为4核8G，接口响应时间大约为200~300ms，每秒可以扛住300~500个请求，数据库机器配置为8核16G，每秒可以扛住800~1000个请求，然后再说你们集群部署了多少台机器，最终能达到一个什么样的效果。
2. 说一下部署架构，更有说服力，比如说：网络分层，DMZ1部署F5、DMZ2部署Nginx+Keepalive+LVS、内网部署整个应用，由Nginx转发请求进来，为了安全考虑，会使用Logstash采集Nginx的日志，通过对日志的分析+Shell脚本，可以完成封禁恶意ip（iptable）等。
3. 再说一下本身项目的实现，比如说MQ具体实现、数据库索引、多级缓存、DDD等亮点。
4. 知识面广的话可以扯一下计算机相关的东西，比如网络（同机房部署，内网IP通信，可以额外新增一条心跳检测专线）、内存（操作尽量在内存中完成）、磁盘IO（尽量顺序读、避免随机读），磁盘架构（raid 10 ，锂电池【防止数据还在OS Cache中，没落盘就断电了】），机房灾备（UPS电源）等等。
5. 把所有知识串起来，一定要加上个人思考，比如说：我这个系统考虑的是高吞吐、低延迟，那么我该使用哪个垃圾收集器？这个就是细节，不然学东西还是学不到点上面去。



###  8. 问：为什么不根据时间来分库分表，而是根据人员ID来分库分库，后期数据量大怎么扩容？

1. 根据时间做，需要按照时间分片进行处理，比较适合处理冷数据。

2. 目前抽奖系统为实时业务数据，如果基于时间分片处理带来的问题是，当一个用户请求进来做业务，很难定位这个用户所属的库表，也包括一些基于人维度的事务处理。

3. 一般基于用户ID所做的分库分表，会根据业务体量的发展设定一个2-3年增量的分库分表规模。比如每个库32张表，分4个库。(PS：这里不要说就4个表、8个表，那你分表还有个P用)

4. 为了因分库分表所带来的服务器资源占用数量，会采用虚机操作，一般一台标C的物理机，进行1虚5的配置进行处理，这样在后续第一波业务爆发增长的时候，可以把虚机换为物理机，这个时候是不需要迁移数据的，成本较低。

5. 当后期数据量较大的时候，采用binlog+canal同步数据的方式进行扩容，并逐步把新数据写入到新库中，当两方数据库完全同步后，开始重启实例进行切换。当然这个成本和风险是会有的，但随着我们的整个流程完整度的提高，在公司内部已经成为标准SOA作业。

6. 当然我们还有一些额外的考虑，怎么做到自动扩展，针对这方面我们目前开始尝试给用户生成的ID中写入库表信息，这个信息是加密的，随着用户量的增多自动扩展数据库表，随着用户体量的增加，挂在后新的用户就可以注册到新库表了。另外，我们还思考，把数据库的路由前置到RPC层，解决数据库笛卡尔积交叉链接的问题，当然这是另外一个场景了，这里就不做过多的扩展了，面试官你看还有其他问题吗。


### 9. 聚合和聚合根在抽奖系统的体现？

以活动入口的规则引擎举例，事件风暴出来的实体对象：树根、子叶、连线，而聚合根是一个整个决策树的描述。（局部和整体）

对于这块的内容，如果是理论，还有一些规则：

聚合设计的尽量小：如果聚合设计的过大，内部还有大量的实体和值对象，管理会比较复杂，高频操作会有并发和数据库锁冲突的问题，导致系统可用性降低； 聚合设计的足够小，也就降低了复杂度，可复用性也更高，降低了后期重构复杂聚合的成本；

聚合应该高内聚：封装的是真正的不变的领域对象，内部的实体和值对象按照固定的规则运行，实现数据的一致性，边界外的任何东西都于该聚合无关。

使用最终一致性：聚合内部数据强一致性，聚合之间数据最终一致性，在一次事务中最多只修改一个聚合的数据状态，如果在一次事务中涉及修改多个聚合的状态，应该使用领域事件的方式来异步的实现最终一致性，实现聚合之间的解耦；


在应用层实现跨聚合的调用(领域编排)：实现微服务内部聚合之间的解耦，以为为未来以聚合为单位的拆分和组合，应该避免跨聚合的的领域服务调用和数据表关联；

### 10.  MVC和DDD的区别?

- MVC：更偏向与数据建模实现，由数据调用驱动，使用也就引申出的DAO、PO、VO类会随着项目开发不断的膨胀，不易于迭代和维护。
- DDD：以业务流程提炼领域模型为驱动，设计和实现模块开发，在一个领域中保护mode对象、仓储数据、服务实现，也更注重设计模式的使用，否则实现的DDD徒有其表更多的知识归类了DAO、PO、VO对象。


### 11. 关于被问到线上有没有出息CPU或者内存飙高等线上问题，让我说说具体的场景以及如何解决的。

场景举例

- 事故级别：P0
- 事故判责：营销活动推广用户较多，影响范围较大，研发整改代码并做复盘。
- 事故名称：秒杀方案独占竞态实现问题
- 事故现象：线上监控突然报警，CPU占用高，拖垮整个服务。用户看到可以购买，但只要一点下单就活动太火爆，换个小手试试。造成了大量客诉，紧急下线活动排查。
- 事故描述：这个一个商品活动秒杀的实现方案，最开始的设计是基于一个活动号ID进行锁定，秒杀时锁定这个ID，用户购买完后就进行释放。但在大量用户抢购时，出现了秒杀分布式锁后的业务逻辑处理中发生异常，释放锁失败。导致所有的用户都不能再拿到锁，也就造成了有商品但不能下单的问题。
事故处理：优化独占竞态为分段静态，将活动ID+库存编号作为动态锁标识。当前秒杀的用户如果发生锁失败那么后面的用户可以继续秒杀不受影响。而失败的锁会有worker进行补偿恢复，那么最终会避免超卖以及不能售卖。
- 学习总结： 核心的技术实现需要经过大量的数据验证以及压测，否则各个场景下很难评估是否会有风险。当然这也不是唯一的实现方案，可以根据不同的场景有不同的实现处理。

独占竞态和分段静态是什么意思？

1. 独占：一个活动一个秒杀锁的key，所有进来的用户都抢这一个key，锁的颗粒度太大，失败风险高。
2. 滑块：一个活动动态生成秒杀key，所有进来的用户抢的是自增key，锁的颗粒度减小，失败风险低。


### 12.  用户领取活动完毕，发送MQ去更新数据库中的库存，这是为了保证缓存和数据库的一致性，但是这里发送MQ为什么不需要像后面的给用户发奖流程一样：考虑发送MQ失败worker补偿、消费MQ失败重试的场景？

1. 用户领取活动的表和活动配置表，不是在一个库，不能做一个事务，除非使用分布式事务。那么这里使用MQ是一种最终一致性的操作。
2. 因为要避免把秒杀都打到库上，因为库的加锁是承受不了多大的独占静态锁的吞吐量的。所以用 MQ 在这里也是消封的作用。
3. 为什么没有 MQ 失败补偿，因为这块逻辑没有额外添加。可以基于落库记录，添加 worker 扫描补偿 MQ 消息。
4. 对于库存扣减的 MQ 也可以通过二次记录缓存，worker定时批量更新数据库，避免较高 MQ 给数据库带来压力。
5. 每个mq的场景都得考虑有补偿机制，一般这个补偿还可以单独有个系统来处理。这样就不用每个系统都开发了。


### 13. 量化规则引擎是一个组件，如果有一个新的业务进来，如何复用? 它的复用性体现在哪?能否支持风控可A/Btest需求?

1. 量化规则引擎的组件设计，本身就是一个独立的领域服务。但什么最开始没有给按照一个单独的系统它拆成独立的微服务呢？因为我们目前的实际业务场景体量还没有那么大，不太适合扩大维护成本，但又考虑将来可能会有其他业务也需要同类的模块，所以以独立的领域进行设计，哪怕以后真的有更大的场景需要使用，也能更加方便的拆分出去独立部署。

2. 它的复用性体现在，它是将同类业务场景中的共性需求，凝练成通用的业务组件，而不是把业务逻辑和功能性服务捆绑，所以在量化规则的库表中配置上相应的渠道和要决策的子节点，再通过子节点的决策树配置，就可以被新的业务场景使用。因为它是规则引擎结构设计，所以灵活性很好，复用性高。
3. A/B Test 本身就可以做为决策树中的节点果实来配置，对AB用户发放不同的策略结果。所以结合风控提供的数据，作为一个逻辑节点使用也是可以的。并且换个节点可以配置到不同的决策树中。
4. 另外决策树也可以进行连接，也就是扩展决策树的果实类型，不是发放结果，而是发放下一个决策树的ID，那么这样还可以把风控作为一个单独的共用决策树使用。其他需要使用风控模型的决策树，配置上即可。


### 14. 项目被问到表的设计？

1. 先介绍业务；抽奖系统作为营销活动平台中的一个环节，承接着活动玩法、积分消耗、奖品发放等系统的纽带，帮助整个业务完成用户的活跃。
2. 后阐述领域；作为一个战略设计的一环，战术实现上要尽可能做到职责隔离，对应系统的具体实现上要拆分出；活动、算法、规则、策略、用户、订单等领域。
3.  引入表设计；根据领域驱动中对各个模块的定义，设计数据库表，也就对应了活动表、抽奖策略配置表、准入规则引擎表、用户抽奖单记录表、以及配合这些表数据结构运行的其他表，如：记录用户的参与次数等。1


### 15. 抽奖和发奖关于库存的扣减，防超发漏发，监控和弥补有没有设计思路和流程图之类的，添加库存，扣减库存的操作日志怎么设计？

1. 在分布式部署下，通常会把活动的库存在活动中时预热到 Redis 缓存中，使用一个Xxxx_id = 100 这样记录库存，当然另外一种方式是不记录库存，使用 Xxxx_id 自增，判断小于总库存即可。
	- 1.1 扣减：因为大部分时候并不会使用数据库去处理集中的锁问题，这样会把数据库拖垮，基本在并发量 tps = 2000 以上，在一个普通配置的数据库下就会发生问题。所以都是基于 Redis incr/decr 的方式来处理，如果说一个方法内包含2个Redis操作，则需要使用 setNx 进行包装。
	
	- 1.2 超卖：在 Redis incr/decr 原子以及 setNx 必要时，是不会发生超卖问题的。但如果说在活动过程中发生 Redis 故障，AOF 同步数据问题以及数据库和缓存同步问题，则需要挂挡板，不允许用户继续参与。PS：任何一个服务类故障，都属于生产事故，以尽可能资损最低的方式处理，降低用户体验。

2. 库存的补充，通常已经上架的活动一般是不允许在线修改的，一个运营事故远大于多售出商品。如果发生线上改库存，通常是运营评估不足，这样的修改情况要发邮件到负责人审批，谁审批谁负责。
   - 2.1 按照真需要添加库存设计，库存的添加操作，需要加锁处理。只能增加库存，不能扣减库存，扣减很可能造成客诉。
   - 2.2 添加库存的时候则需要先更新数据库库存，在同步 Redis 库存。
   - 2.3 挡板；为了安全起见，在一些数据恢复、库存变更时，则需要添加挡板，直至库存变更完毕，才重新上架活动，在此期间用户只能看见一个比较温馨的提示。PS：商家紧急补货中，喝口小茶再来秒杀！

3. 日志管理方面，其实通常来说都是一套统一的日志管理，采用非入侵的全链路监控进行处理，另外可以把运营的操作，活动的库存变更，记录日志。必要时可以保护研发


### 16. 路由散列算法设计

int dbIdx = idx / tbCount + 1;
int tbIdx = idx - tbCount * (dbIdx - 1);
 
库表路由计算

这个是开发基础中最常见的逻辑，如果自己做过CRUD中的分页功能会很清楚。
对于分页来说，输入的是总条数和每页的数量，从而通过类似的逻辑，就可以知道分几页，以及根据当然页计算每条数据的偏移量。
对于分库分表来说，那个逻辑本质就是一个二维数组索引的定位，比如16*16的棋盘。先定位在哪行，在定位在哪个列。同理，先定位库，在定位表。
假设idx=25，tbcount=10，说明提供的是一个全局偏移量，和每行的数量，那么定位行数或者库，就是第一行的代码。同理定位列的数量或者表的位置，就是第2行的代码。

1. 思想上；是把 HashMap 的拉链结构转换到库和表的结构上
2. 实现上；通过哈希计算散列值后，通过库表的总和来均分计算该属于哪个区间。


### 17. 抽奖概率是100百万怎么处理？

问题描述： ipad中奖概率为1/1000000，苹果手机中奖概率为1/1000000，其他的999998/1000000均为不中奖。那这种情况new一个长度大于1000000的数组然后散列进去那肯定不合适。


1. 把散列的值做成一个key，写到redis里就可以。
   
其实就是把数据模拟到redis里就可以了，比如你先把奖品散列到key上，
lottery-key-23109110-0000001 = IPhone
lottery-key-23109110-0000002 = 无奖品
lottery-key-23109110-0000003 = 无奖品
lottery-key-23109110-0000004 = airpods
...
lottery-key-23109110-1000000 = 兜底奖品

空的key无奖品，也可以不生成。之后抽奖就从1百万中产生或者是分配成几次生成后的乘积都可以。

2. 做一些自定义的数据分段，比如1-10000存在bitmap1字段中，10001-20000存在bitmap2中，...

使用位图来判断。

意思是字段报考这些数据，将奖品生成的字段去判断即可。



### 18. 抽奖码，1-999999的抽签码的实现

1. redis set 来处理，内存占用偏高
2. 使用位图来 判断，然后快速查找就使用hash来判断，例子如下
一共100w条数据  
按照1000条为一段 
hash存储个数为1000
存储key样例 1∶1
当某个段全部使用完成 存储格式就是1:1000
针对用户端来说只是要相对随机
所以在服务端可以直接做轮训获取操作的hash  key  

这些操作保证原子性


3. 如果用户量不大，不去需要使用分库分表的话。
	- 提供一个抽奖码数据库表，生成的随机码记录到抽奖表，同时记录一个自增的数字，这样就能知道从1到n有多个随机抽奖码。
	- 每个用户身上记录抽奖码，可以是一个也可以是多个，记录在自己身上。
	-  抽奖开始时候，不用抽奖码，用的是1~n的范围，基于这些范围比如1-10000，从中随机去除10个，那么这个10个数字对应的码就是抽奖码，在用抽奖码匹配到个人身上，修改状态为中奖。



### 19. 项目向内部应用提供了RPC接口，那么当h5端需要提供一个http的请求，这个接口应该写在哪里呢？

一般不会在业务系统的RPC服务中直接提供给H5、Web、App使用的HTTP接口，而是单独提供一个这样的API工程用于包装这些接口。例如项目的网关API。


### 20. 如果redis作为分布式锁的时候，主节点挂掉了，但是数据还没有同步到从节点，这种情况怎么办？

1. 通常这种情况也就是说主节点挂了，切换到从节点也不能正常工作。那么最要保障的就是不要发生过多的客诉，所以会紧急上挡板，下线活动，提醒用户：“商品售空，运营正在紧急补货中，稍后上架”。待Redis等服务恢复后，再进行上线。
2. 另外一般我们为了防止这样的情况，会在Redis互备的基础上，还会做Redis双写控制，这两套Redis是完成隔离的，也就是能包装至少在3个9以上的可用率，如果再出问题，走1的流程。

### 21. 活动库存与奖品库存的配置关系？

活动库存用完后，奖品库存还有剩余。

库存是控制运营成本上限的，运营人员会配置活动库存、奖品库存、兜底奖品、活动人群等，来做调整以让活动达到最佳的效果。所有的运营都是有运营目的性的，不是随便撒钱。

### 22. 市场上成熟的规则引擎组件？

规则引擎，还有基于 Rete 算法实现的 Drools 非常常用，另外一些小众的；EasyRule 以及像工作流相关的 activity7 也可以当做规则引擎使用。


### 23. 为什么使用斐波拉契抽奖算法，而不是使用顺序表存储？

 这两种空间和时间复杂度是一样的。

可以说是了在减少数据空间使用功能的情况下增加散列效果，存放奖品时使用斐波那契计算索引，获取奖品时直接Random随机一个位置抽奖。


### 24. 定时任务补偿MQ需要循环扫描表中的所有数据，如果表中的数据过多，扫描一遍很慢，怎么解决？

分布式任务扫描数据可以查询出未处理任务的最大的id，之后根据id > ? 来查询，减少扫描数量。另外对于任务的处理，还可以设计一个单独的表，这样的就可以已经处理完的n个周的数据，进行迁移。


### 25. 采用定时任务扫描的方式，如何保证活动准时开启和关闭呢？使用轮循的方式，感觉总是会有延迟的吧

提前5分钟把活动扫描为活动中，在使用活动的时候，根据状态和时间个字段判断，如果设定的开始时间未到，则活动也展示为未开始。

另外如果是一些必须精准处理的任务，可以使用延迟队列设计，

### 26. 想要在项目里使用一点并发编程相关的知识，可以在哪里添加呀，比如说线程池，AQS锁什么的？

其实分布式的设计是尽可能降低对1台机器的压榨，而是把任务分散到多台实例上，所以你自己处理的业务是几乎没有非得用多线程的，而是用分布式算力替代了多线程。

那么还有一些必须使用的场景，多数是池化类设计，比如；JDBC连接池、多线程数据查询汇总等。你可以举例说自己给APP提供的接口有多个接口需要汇总数据调用，暂时又不好调整数据结构，因而需要使用多线程来处理数据查询。


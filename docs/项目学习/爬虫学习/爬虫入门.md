# 爬虫入门

空格间距用固定好

### 修改网络代理

设置里HTTP Proxy 中

``https://plugins.jetbrains.com/``


### User-Agent 用户代理

其实就是重构了User-Agent，防止网站识别

### 构建代理池


### URL 编码和解码


URL 中规定了一些具有特殊意义的字符，常被用来分隔两个不同的 URL 组件，这些字符被称为保留字符。例如：
- 冒号：用于分隔协议和主机组件，斜杠用于分隔主机和路径
- ?：用于分隔路径和查询参数等。
- =用于表示查询参数中的键值对。
- &符号用于分隔查询多个键值对。

**url拼接**
{} 占位符
```py
# 1、字符串相加
  baseurl = 'http://www.baidu.com/s?'
  params='wd=%E7%88%AC%E8%99%AB'
  url = baseurl + params
# 2、字符串格式化（占位符）
  params='wd=%E7%88%AC%E8%99%AB'
  url = 'http://www.baidu.com/s?%s'% params
# 3、format()方法
  url = 'http://www.baidu.com/s?{}'
  params='wd=%E7%88%AC%E8%99%AB'
  url = url.format(params)
```

### 爬虫程序结构

```py
# 程序结构
class xxxSpider(object):
    def __init__(self):
        # 定义常用变量,比如url或计数变量等
       
    def get_html(self):
        # 获取响应内容函数,使用随机User-Agent
   
    def parse_html(self):
        # 使用正则表达式来解析页面，提取数据
   
    def write_html(self):
        # 将提取的数据按要求保存，csv、MySQL数据库等
       
    def run(self):
        # 主函数，用来控制整体逻辑
       
if __name__ == '__main__':
    # 程序开始运行时间
    spider = xxxSpider()
    spider.run()
```

### re模块

### requests库请求

